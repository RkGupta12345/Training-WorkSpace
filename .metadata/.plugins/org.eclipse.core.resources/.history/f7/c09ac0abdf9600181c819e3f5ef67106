package com.training.sparkworks;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import static org.apache.spark.sql.functions.*;

import com.training.commons.SparkConnection;

public class SparkSqlDemo {

	public static void main(String[] args) {
		Logger.getLogger("org").setLevel(Level.ERROR);
		Logger.getLogger("akka").setLevel(Level.ERROR);
		JavaSparkContext sparkContext= SparkConnection.getContext();
		
		SparkSession spSession=SparkConnection.getSession();
		Dataset<Row> empDataFields=spSession.read().json("./data/customerData.json");
		
		empDataFields.show();
		empDataFields.printSchema();
		
		// data queries
		
		System.out.println("Select Demo::::");
		
		empDataFields.select(col("name"),col("salary")).show();
		
		// data 
		
		System.out.println("Select Demo With Condition::::");
		empDataFields.filter(col("gender").equalTo("male")).show();
		
		System.out.println("Aggerate - group BY Gender:::::");
		empDataFields.groupBy(col("gender")).count().show();
	}

}
